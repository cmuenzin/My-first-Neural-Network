{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Python Neuronales Netz**\n\nKonstruktion eines neuronalen Netzes mit 2 Layern das lernen soll die Zahlen im MNIST Data Set korrekt zu kategorisieren\n\n# Zielsetzung\n\nDas Netz soll mit einem Teil der Daten trainiert werden um möglichst eindeutig zu kategorisieren\n\n# Über die Daten\n\nDas MNIST Set besteht aus tausenden 28 x 28 Pixel Sets (also insgesamt 784 Pixel pro Set) Auf den Pixel Grids ist in Grayscale eine Zahl von 0-9 abgebildet. Ist ein Pixel schwarz hat es den Wert 0, ist es weiß hat es den Wert 255. In der Matrix der Daten steht jede Spalte hinter der ersten für eines der 784 Pixel. In der ersten Spalte steht die Zahl die abgebildet ist - die Lösung. Folglich ist jede Zeile ein Datenset für ein 28x28 Grid","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nfrom matplotlib import pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Daten aus dem MNIST Set importieren\ndata = pd.read_csv('/kaggle/input/digit-recognizer/train.csv')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Daten organisieren**\n1. Die Daten aus dem csv format sollen von einer pandas matrix zu einem numpy array umformatiert werden\n2. Die Anzahl der Zeilen und Spalten sollte für spätere Verwendung zwischengespeichert werden - Jede Zeile ist dabei ein gesamtes Datenset, also die Menge der Pixel und der Lösungswert. Jede Spalte, mit Ausnahme der Lösung, ist jeweils einem Pixel im Raster zugeordnet\n\n3. Die Daten Sets sollten vor Verwendung gemischt werden\n4. Die Daten sollten aufgeteilt werden in training und dev data\n5. Für spätere Berechnungen ist es vorteilhafter die Matrizen jeweils zu transponieren\n","metadata":{}},{"cell_type":"code","source":"# Daten von pandas matrix format zu numpy array umformatieren\ndata = np.array(data)\n\n# Die Anzahl an Zeilen und Spalten zwischenspeichern\nm, n = data.shape\n\n# Daten mischen\nnp.random.shuffle(data)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dev Data aussortieren\ndev_data = data[0:1000]\n# Dev Data transponieren\ndev_data = dev_data.T\n\n# Bereich der dev Data speichern\n# Erste Zeile\nYdev = dev_data[0]\n# Alle Pixel (die erste Spalte ist ausgenommen, da sie die Lösung enthält)\nXdev = dev_data[1:n]\n\n# Warum ich das brauche hab ich noch nicht verstanden\nXdev = Xdev / 255. ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training Data \ntrain_data = data[1000:m]\ntrain_data = train_data.T\n\n# Erste Zeile\nYtrain = train_data[0]\n# Alle Pixel \nXtrain = train_data[1:n]\n\n# Warum ich das brauche hab ich noch nicht verstanden\nXtrain = Xtrain / 255. \n\n# Dimension der training Data zwischenspeichern\n_,mtrain = Xtrain.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Forward Propagation**\n\nInput Layer\n$A^{[0]}$ = X\n\n$A^{[0]}$ ist dabei die Matric des Input Layers mit den Dimensionen 784 x m\n\nFirst Layer / Hidden Layer\n$$Z^{[1]} = W^{[1]} X + b^{[1]}$$\n\n$$Z^{[1]}$$ ist dabei die Matrix des Hidden Layers mit den Dimensionen 10 (Anzahl der Knoten im Netz) x m \nW^{[1]} ist dabei ","metadata":{}},{"cell_type":"code","source":"def init_params():\n    W1 = np.random.rand(10, 784) - 0.5\n    b1 = np.random.rand(10, 1) - 0.5\n    W2 = np.random.rand(10, 10) - 0.5\n    b2 = np.random.rand(10, 1) - 0.5\n    return W1, b1, W2, b2\n\ndef ReLU(Z):\n    return np.maximum(Z, 0)\n\ndef softmax(Z):\n    A = np.exp(Z) / sum(np.exp(Z))\n    return A\n    \ndef forward_prop(W1, b1, W2, b2, X):\n    Z1 = W1.dot(X) + b1\n    A1 = ReLU(Z1)\n    Z2 = W2.dot(A1) + b2\n    A2 = softmax(Z2)\n    return Z1, A1, Z2, A2\n\ndef ReLU_deriv(Z):\n    return Z > 0\n    \ndef one_hot(Y):\n    one_hot_Y = np.zeros((Y.size, Y.max() + 1))\n    one_hot_Y[np.arange(Y.size), Y] = 1\n    one_hot_Y = one_hot_Y.T\n    return one_hot_Y\n\ndef backward_prop(Z1, A1, Z2, A2, W1, W2, X, Y):\n    one_hot_Y = one_hot(Y)\n    dZ2 = A2 - one_hot_Y\n    dW2 = 1 / m * dZ2.dot(A1.T)\n    db2 = 1 / m * np.sum(dZ2)\n    dZ1 = W2.T.dot(dZ2) * ReLU_deriv(Z1)\n    dW1 = 1 / m * dZ1.dot(X.T)\n    db1 = 1 / m * np.sum(dZ1)\n    return dW1, db1, dW2, db2\n\ndef update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha):\n    W1 = W1 - alpha * dW1\n    b1 = b1 - alpha * db1    \n    W2 = W2 - alpha * dW2  \n    b2 = b2 - alpha * db2    \n    return W1, b1, W2, b2","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_predictions(A2):\n    return np.argmax(A2, 0)\n\ndef get_accuracy(predictions, Y):\n    print(predictions, Y)\n    return np.sum(predictions == Y) / Y.size\n\ndef gradient_descent(X, Y, alpha, iterations):\n    W1, b1, W2, b2 = init_params()\n    for i in range(iterations):\n        Z1, A1, Z2, A2 = forward_prop(W1, b1, W2, b2, X)\n        dW1, db1, dW2, db2 = backward_prop(Z1, A1, Z2, A2, W1, W2, X, Y)\n        W1, b1, W2, b2 = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha)\n        if i % 10 == 0:\n            print(\"Iteration: \", i)\n            predictions = get_predictions(A2)\n            print(get_accuracy(predictions, Y))\n    return W1, b1, W2, b2","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"W1, b1, W2, b2 = gradient_descent(X_train, Y_train, 0.10, 500)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_predictions(X, W1, b1, W2, b2):\n    _, _, _, A2 = forward_prop(W1, b1, W2, b2, X)\n    predictions = get_predictions(A2)\n    return predictions\n\ndef test_prediction(index, W1, b1, W2, b2):\n    current_image = X_train[:, index, None]\n    prediction = make_predictions(X_train[:, index, None], W1, b1, W2, b2)\n    label = Y_train[index]\n    print(\"Prediction: \", prediction)\n    print(\"Label: \", label)\n    \n    current_image = current_image.reshape((28, 28)) * 255\n    plt.gray()\n    plt.imshow(current_image, interpolation='nearest')\n    plt.show()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_prediction(0, W1, b1, W2, b2)\ntest_prediction(1, W1, b1, W2, b2)\ntest_prediction(2, W1, b1, W2, b2)\ntest_prediction(3, W1, b1, W2, b2)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dev_predictions = make_predictions(X_dev, W1, b1, W2, b2)\nget_accuracy(dev_predictions, Y_dev)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As first developed by Samson Zhang","metadata":{}}]}